{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###**Описание задачи:**\n",
        "Восстановить пропущенные пробелы в текстах объявлений, где слова слиты в одну строку."
      ],
      "metadata": {
        "id": "jJSyOoCbkf03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Предлагаемое решение**\n",
        "Гибридный подход, комбинирующий сильные стороны разных методов через взвешенное голосование. Каждый метод вносит свой вклад в окончательное решение, что позволяет достичь максимальной точности.\n",
        "\n",
        "###**Почему этот подход эффективен?**\n",
        "Гибридный подход эффективен благодаря совмещению четырех методов:\n",
        "*   Словарный поиск - Быстрое покрытие известных слов\n",
        "\n",
        "*   Алгоритм Витерби - Глобальная оптимизация разбиения\n",
        "\n",
        "*   Распознавание паттернов - Точечное решение специфичных случаев\n",
        "\n",
        "*   Лингвистические эвристики - Вспомогательная проверка"
      ],
      "metadata": {
        "id": "M_90a1EBlStt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Словарь**\n",
        "\n",
        "Словарь специально подобран для объявлений Avito и включает:\n",
        "\n",
        "*   Действия: куплю, продам, сдам, ищу, сниму\n",
        "\n",
        "*   Недвижимость: квартира, дом, комната, офис, гараж\n",
        "\n",
        "*   Техника: айфон, телефон, ноутбук, телевизор\n",
        "\n",
        "*   Мебель: диван, кровать, стол, стул, шкаф\n",
        "\n",
        "*   Транспорт: машина, авто, велосипед\n",
        "\n",
        "*   Прилагательные: новый, б/у, срочно, недорого\n",
        "\n",
        "*   Локации: москва, питер, метро, центр\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wJYOH1bLmVIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Анализ алгоритма:**\n",
        "\n",
        "Суть алгоритма:\n",
        "\n",
        "*   Параллелизм: Четыре независимых метода анализируют текст одновременно\n",
        "\n",
        "*   Взвешенное решение: Каждый метод вносит вклад согласно своей надежности\n",
        "\n",
        "*   Интеллектуальная фильтрация: Удаление неправдоподобных разбиений по лингвистическим правилам\n",
        "\n",
        "Преимущества:\n",
        "*   Компенсация слабостей: Каждый метод покрывает недостатки других\n",
        "*   Доменная оптимизация: Специализация под лексику Avito\n",
        "*   Воспроизводимость: Детерминированные алгоритмы, прозрачная логика\n",
        "\n",
        "Ключевое значение здесь играет качетво словаря, спецификация под домен Авито и его объем (от него зависит и словарный поиск и алгоритм Витерби, который может подстроиться под \"шум\" словаря). Пример словаря я попросил сгенерировать LLM (в силу ограниченности времени), что не способствовало высокому показателю метрики.\n",
        "Распознавание же паттернов тоже весьма ограничено - требует ручной прописи всех возможных паттернов.\n",
        "Однако, в целом данный подход имеет значительное преимущество в скорости в сравнении с большими, тяжеловестными, например, BERT-like моделями."
      ],
      "metadata": {
        "id": "gPgNaWR9nk-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Воспроизведение:**\n",
        "Воспроизвести можно, например, в Colab положив рядом файл с датасетом dataset_1937770_3.txt"
      ],
      "metadata": {
        "id": "CtBEG9OdvVhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Hybrid Quality Solution for Space Restoration - Combined Approach\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "class HybridSpaceRestorer:\n",
        "    \"\"\"\n",
        "    Гибридный восстановитель пробелов, объединяющий:\n",
        "    1. Словарный поиск\n",
        "    2. Алгоритм Витерби с Avito-словарем\n",
        "    3. Лингвистические эвристики\n",
        "    4. Паттерны и правила\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Загружаем оба словаря\n",
        "        self.fast_dict = self._load_comprehensive_dictionary()\n",
        "        self.avito_dict = self._create_avito_corpus([])  # Будет обновлен позже\n",
        "        self.patterns = self._load_patterns()\n",
        "\n",
        "        # Параметры для взвешивания методов\n",
        "        self.dict_weight = 0.6\n",
        "        self.viterbi_weight = 0.3\n",
        "        self.heuristic_weight = 0.1\n",
        "\n",
        "    def _load_comprehensive_dictionary(self):\n",
        "        \"\"\"Расширенный словарь русских слов для Avito\"\"\"\n",
        "        words = [\n",
        "            # Глаголы и действия (самые частые)\n",
        "            'куплю', 'продам', 'сдам', 'ищу', 'сниму', 'меняю', 'отдам', 'приму',\n",
        "            'покупаю', 'продаю', 'сдаю', 'ищем', 'снимаем', 'меняем',\n",
        "            'ремонт', 'услуги', 'заказ', 'доставка', 'продажа', 'покупка', 'обмен',\n",
        "\n",
        "            # Недвижимость\n",
        "            'квартира', 'дом', 'комната', 'офис', 'гараж', 'участок', 'дача', 'студия',\n",
        "            'апартаменты', 'таунхаус', 'коттедж', 'балкон', 'кухня', 'санузел', 'гостиная',\n",
        "            'спальня', 'ванная', 'коридор', 'кладовая', 'мастерская',\n",
        "\n",
        "            # Техника и электроника\n",
        "            'айфон', 'телефон', 'смартфон', 'ноутбук', 'компьютер', 'телевизор',\n",
        "            'холодильник', 'стиральная', 'посудомойка', 'микроволновка', 'пылесос',\n",
        "            'кофемашина', 'утюг', 'фен', 'блендер', 'миксер', 'мясорубка', 'чайник',\n",
        "            'роутер', 'планшет', 'камера', 'наушники', 'колонки', 'монитор',\n",
        "\n",
        "            # Мебель\n",
        "            'диван', 'кровать', 'стол', 'стул', 'шкаф', 'комод', 'полка', 'кресло',\n",
        "            'тумба', 'стеллаж', 'пуф', 'банкетка', 'сервант', 'буфет', 'гарнитур',\n",
        "\n",
        "            # Транспорт\n",
        "            'машина', 'авто', 'автомобиль', 'велосипед', 'мотоцикл', 'скутер',\n",
        "            'самокат', 'гироскутер', 'электросамокат',\n",
        "\n",
        "            # Прилагательные и характеристики\n",
        "            'новый', 'новая', 'новое', 'б/у', 'бу', 'срочно', 'недорого', 'дешево',\n",
        "            'дорого', 'отличный', 'хороший', 'качественный', 'евро', 'оригинал',\n",
        "            'рабочий', 'исправный', 'чистый', 'аккуратный', 'современный', 'стильный',\n",
        "\n",
        "            # Местоположение\n",
        "            'москва', 'питер', 'спб', 'подмосковье', 'область', 'центр', 'метро',\n",
        "            'мкад', 'садовая', 'невский', 'арбат', 'тверская', 'ленинский', 'проспект',\n",
        "\n",
        "            # Единицы измерения и цены\n",
        "            'руб', 'рублей', 'долларов', 'евро', 'шт', 'см', 'м', 'мм', 'кг', 'л', 'кв',\n",
        "            'цена', 'стоимость', 'бюджет', 'скидка', 'акция', 'распродажа',\n",
        "\n",
        "            # Профессии и услуги\n",
        "            'работа', 'вакансия', 'требуется', 'ищем', 'грузчик', 'водитель', 'курьер',\n",
        "            'разнорабочий', 'строитель', 'отделочник', 'сантехник', 'электрик',\n",
        "            'мастер', 'специалист', 'опыт', 'образование',\n",
        "\n",
        "            # Разное\n",
        "            'кошка', 'собака', 'котенок', 'щенок', 'аквариум', 'клетка', 'переноска',\n",
        "            'игрушки', 'одежда', 'обувь', 'куртка', 'платье', 'джинсы', 'футболка'\n",
        "        ]\n",
        "\n",
        "        return set(words)\n",
        "\n",
        "    def _create_avito_corpus(self, texts):\n",
        "        \"\"\"Создаем Avito-ориентированный словарь (из второго подхода)\"\"\"\n",
        "        avito_categories = {\n",
        "            'недвижимость': [\n",
        "                'куплю', 'продам', 'сниму', 'сдам', 'аренда', 'посуточно', 'квартира',\n",
        "                'комната', 'дом', 'дача', 'гараж', 'офис', 'студия', 'новостройка',\n",
        "                'вторичка', 'ипотека', 'залог', 'без', 'посредников', 'собственник',\n",
        "            ],\n",
        "            'транспорт': [\n",
        "                'купить', 'продать', 'авто', 'машина', 'автомобиль', 'бушный', 'новый',\n",
        "                'подержанный', 'пробег', 'год', 'выпуска', 'цвет', 'двигатель',\n",
        "            ],\n",
        "            'электроника': [\n",
        "                'телефон', 'смартфон', 'айфон', 'iphone', 'самсунг', 'samsung', 'xiaomi',\n",
        "                'ноутбук', 'компьютер', 'пк', 'планшет', 'ipad', 'телевизор',\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        all_words = []\n",
        "        for category in avito_categories.values():\n",
        "            all_words.extend(category)\n",
        "\n",
        "        # Добавляем слова из текстов\n",
        "        for text in texts:\n",
        "            words = re.findall(r'[а-яё]{3,12}', text.lower())\n",
        "            all_words.extend(words)\n",
        "\n",
        "        word_freq = Counter(all_words)\n",
        "\n",
        "        # Нормализуем частоты\n",
        "        if word_freq:\n",
        "            max_freq = max(word_freq.values())\n",
        "            for word in word_freq:\n",
        "                word_freq[word] = word_freq[word] / max_freq * 1000000\n",
        "\n",
        "        return word_freq\n",
        "\n",
        "    def _load_patterns(self):\n",
        "        \"\"\"Загружаем паттерны для поиска\"\"\"\n",
        "        return {\n",
        "            'prices': [r'\\d+руб', r'\\d+р', r'\\d+₽', r'\\d+\\$', r'\\d+USD', r'\\d+евро'],\n",
        "            'sizes': [r'\\d+см', r'\\d+м', r'\\d+мм', r'\\d+кв', r'\\d+л', r'\\d+кг'],\n",
        "            'phones': [r'\\d{11}', r'\\d{10}', r'\\d{7}'],\n",
        "            'dates': [r'\\d{2}\\.\\d{2}', r'\\d{2}\\.\\d{2}\\.\\d{4}']\n",
        "        }\n",
        "\n",
        "    def fit(self, texts):\n",
        "        \"\"\"Обучение на текстах (обновление Avito-словаря)\"\"\"\n",
        "        self.avito_dict = self._create_avito_corpus(texts)\n",
        "        print(f\"Обучен Avito-словарь на {len(texts)} текстах\")\n",
        "\n",
        "    def word_probability_avito(self, word):\n",
        "        \"\"\"Вероятность слова в Avito-контексте\"\"\"\n",
        "        word_lower = word.lower()\n",
        "\n",
        "        if word_lower in self.avito_dict:\n",
        "            base_prob = np.log(self.avito_dict[word_lower] + 1)\n",
        "\n",
        "            # Бонусы для Avito-ключевых слов\n",
        "            avito_keywords = ['куплю', 'продам', 'сдам', 'сниму', 'ищу', 'бу', 'новый', 'срочно']\n",
        "            if word_lower in avito_keywords:\n",
        "                base_prob += 3\n",
        "\n",
        "            return base_prob\n",
        "        else:\n",
        "            # Штраф для неизвестных слов\n",
        "            penalty = -len(word) * 2\n",
        "            if re.match(r'^[а-яё]+$', word_lower):\n",
        "                penalty += 1\n",
        "            if len(word) <= 2:\n",
        "                penalty -= 15\n",
        "            return penalty\n",
        "\n",
        "    def viterbi_search(self, text):\n",
        "        \"\"\"Алгоритм Витерби для поиска оптимального разбиения\"\"\"\n",
        "        n = len(text)\n",
        "        if n < 3:\n",
        "            return []\n",
        "\n",
        "        # Инициализация\n",
        "        dp = [-float('inf')] * (n + 1)\n",
        "        dp[0] = 0\n",
        "        prev = [None] * (n + 1)\n",
        "\n",
        "        max_word_len = 12\n",
        "\n",
        "        for i in range(1, n + 1):\n",
        "            for j in range(max(0, i - max_word_len), i):\n",
        "                if j < 0:\n",
        "                    continue\n",
        "\n",
        "                word = text[j:i]\n",
        "                prob = self.word_probability_avito(word)\n",
        "\n",
        "                if dp[j] + prob > dp[i]:\n",
        "                    dp[i] = dp[j] + prob\n",
        "                    prev[i] = j\n",
        "\n",
        "        # Восстановление позиций\n",
        "        spaces = []\n",
        "        i = n\n",
        "        while i > 0:\n",
        "            j = prev[i]\n",
        "            if j is not None and j > 0:\n",
        "                spaces.append(j - 1)\n",
        "            i = j\n",
        "            if i is None:\n",
        "                break\n",
        "\n",
        "        return sorted(spaces)\n",
        "\n",
        "    def dictionary_search(self, text):\n",
        "        \"\"\"Быстрый словарный поиск (из первого подхода)\"\"\"\n",
        "        spaces = []\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Ищем самые длинные слова сначала\n",
        "        words_sorted = sorted(self.fast_dict, key=len, reverse=True)\n",
        "\n",
        "        i = 0\n",
        "        while i < len(text):\n",
        "            found = False\n",
        "            for word in words_sorted:\n",
        "                if len(word) <= len(text) - i and text_lower[i:i+len(word)] == word:\n",
        "                    if i + len(word) < len(text):\n",
        "                        spaces.append(i + len(word))\n",
        "                    i += len(word)\n",
        "                    found = True\n",
        "                    break\n",
        "\n",
        "            if not found:\n",
        "                i += 1\n",
        "\n",
        "        return spaces\n",
        "\n",
        "    def pattern_search(self, text):\n",
        "        \"\"\"Поиск паттернов (цены, размеры и т.д.)\"\"\"\n",
        "        spaces = []\n",
        "\n",
        "        # Цены и размеры\n",
        "        for pattern_type in ['prices', 'sizes']:\n",
        "            for pattern in self.patterns[pattern_type]:\n",
        "                for match in re.finditer(pattern, text):\n",
        "                    if match.start() > 0:\n",
        "                        spaces.append(match.start())\n",
        "\n",
        "        return spaces\n",
        "\n",
        "    def russian_heuristics(self, text):\n",
        "        \"\"\"Лингвистические эвристики для русского языка\"\"\"\n",
        "        spaces = []\n",
        "\n",
        "        vowels = 'аеёиоуыэюя'\n",
        "        consonants = 'бвгджзйклмнпрстфхцчшщ'\n",
        "\n",
        "        # Эвристика: после предлогов\n",
        "        short_words = ['в', 'на', 'за', 'под', 'над', 'от', 'до', 'по', 'со', 'из', 'не', 'без']\n",
        "        for word in short_words:\n",
        "            start = 0\n",
        "            while True:\n",
        "                pos = text.find(word, start)\n",
        "                if pos == -1:\n",
        "                    break\n",
        "                if pos + len(word) < len(text):\n",
        "                    next_char = text[pos + len(word)]\n",
        "                    if next_char.lower() in consonants:\n",
        "                        spaces.append(pos + len(word))\n",
        "                start = pos + 1\n",
        "\n",
        "        # Эвристика: границы слов по чередованию гласных-согласных\n",
        "        for i in range(2, len(text) - 2):\n",
        "            if (text[i] in consonants and text[i+1] in vowels and\n",
        "                text[i-1] in vowels and text[i+2] in consonants):\n",
        "                if i + 1 not in spaces:\n",
        "                    spaces.append(i + 1)\n",
        "\n",
        "        return spaces\n",
        "\n",
        "    def number_search(self, text):\n",
        "        \"\"\"Поиск и обработка чисел\"\"\"\n",
        "        spaces = []\n",
        "\n",
        "        for match in re.finditer(r'\\d+', text):\n",
        "            start, end = match.span()\n",
        "\n",
        "            if start > 0:\n",
        "                spaces.append(start)\n",
        "\n",
        "            if end < len(text):\n",
        "                next_part = text[end:end+3]\n",
        "                if not any(pattern in next_part for pattern in ['руб', 'р', 'см', 'м', 'кг', 'л', 'кв']):\n",
        "                    spaces.append(end)\n",
        "\n",
        "        return spaces\n",
        "\n",
        "    def combine_results(self, text, all_spaces):\n",
        "        \"\"\"Комбинирование результатов от разных методов\"\"\"\n",
        "        if not all_spaces:\n",
        "            return []\n",
        "\n",
        "        # Собираем все предложенные позиции с весами\n",
        "        space_scores = {}\n",
        "\n",
        "        # Метод 1: Словарный поиск (высокий вес)\n",
        "        dict_spaces = set(all_spaces.get('dictionary', []))\n",
        "        for space in dict_spaces:\n",
        "            space_scores[space] = space_scores.get(space, 0) + self.dict_weight\n",
        "\n",
        "        # Метод 2: Витерби (средний вес)\n",
        "        viterbi_spaces = set(all_spaces.get('viterbi', []))\n",
        "        for space in viterbi_spaces:\n",
        "            space_scores[space] = space_scores.get(space, 0) + self.viterbi_weight\n",
        "\n",
        "        # Метод 3: Эвристики (низкий вес)\n",
        "        heuristic_spaces = set(all_spaces.get('heuristics', []))\n",
        "        for space in heuristic_spaces:\n",
        "            space_scores[space] = space_scores.get(space, 0) + self.heuristic_weight\n",
        "\n",
        "        # Метод 4: Паттерны (высокий вес для найденных)\n",
        "        pattern_spaces = set(all_spaces.get('patterns', []))\n",
        "        for space in pattern_spaces:\n",
        "            space_scores[space] = space_scores.get(space, 0) + 0.8  # Высокий вес\n",
        "\n",
        "        # Отбираем позиции с достаточным весом\n",
        "        threshold = 0.3\n",
        "        candidate_spaces = [space for space, score in space_scores.items()\n",
        "                          if score >= threshold]\n",
        "\n",
        "        return self._filter_spaces(text, candidate_spaces)\n",
        "\n",
        "    def _filter_spaces(self, text, spaces):\n",
        "        \"\"\"Фильтрация пробелов\"\"\"\n",
        "        if not spaces:\n",
        "            return []\n",
        "\n",
        "        unique_spaces = sorted(set(spaces))\n",
        "        filtered = []\n",
        "        prev_space = -3\n",
        "\n",
        "        for space in unique_spaces:\n",
        "            # Проверяем минимальное расстояние\n",
        "            if space - prev_space >= 2 and 1 <= space < len(text):\n",
        "                # Проверяем, что не разбиваем числа или английские слова\n",
        "                if not (space > 0 and text[space-1].isdigit() and\n",
        "                       space < len(text) and text[space].isdigit()):\n",
        "                    if not (text[space-1].isalpha() and text[space].isalpha() and\n",
        "                           text[space-1].isascii() and text[space].isascii()):\n",
        "                        filtered.append(space)\n",
        "                        prev_space = space\n",
        "\n",
        "        return filtered\n",
        "\n",
        "    def restore_spaces(self, text):\n",
        "        \"\"\"Основной метод восстановления пробелов\"\"\"\n",
        "        if not text or len(text) < 3:\n",
        "            return []\n",
        "\n",
        "        # Очищаем текст\n",
        "        clean_text = self._clean_text(text)\n",
        "        if len(clean_text) < 3:\n",
        "            return []\n",
        "\n",
        "        # Применяем все методы\n",
        "        all_spaces = {}\n",
        "\n",
        "        # 1. Быстрый словарный поиск\n",
        "        all_spaces['dictionary'] = self.dictionary_search(clean_text)\n",
        "\n",
        "        # 2. Алгоритм Витерби\n",
        "        all_spaces['viterbi'] = self.viterbi_search(clean_text)\n",
        "\n",
        "        # 3. Лингвистические эвристики\n",
        "        all_spaces['heuristics'] = self.russian_heuristics(clean_text)\n",
        "\n",
        "        # 4. Поиск паттернов\n",
        "        all_spaces['patterns'] = self.pattern_search(clean_text)\n",
        "\n",
        "        # 5. Поиск чисел\n",
        "        all_spaces['numbers'] = self.number_search(clean_text)\n",
        "\n",
        "        # Комбинируем результаты\n",
        "        final_spaces = self.combine_results(clean_text, all_spaces)\n",
        "\n",
        "        return final_spaces\n",
        "\n",
        "    def _clean_text(self, text):\n",
        "        \"\"\"Очищаем текст от ID\"\"\"\n",
        "        if re.match(r'^\\d+,', text):\n",
        "            return text.split(',', 1)[1]\n",
        "        return text\n",
        "\n",
        "def load_data(filename):\n",
        "    \"\"\"Загружаем данные с обработкой запятых\"\"\"\n",
        "    data = []\n",
        "    with open(filename, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "        for line in lines[1:]:\n",
        "            parts = line.strip().split(',', 1)\n",
        "            if len(parts) == 2:\n",
        "                data.append(parts)\n",
        "            else:\n",
        "                data.append([parts[0], ' '.join(parts[1:])])\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['id', 'text_no_spaces'])\n",
        "    df['id'] = df['id'].astype(int)\n",
        "    return df\n",
        "\n",
        "def create_hybrid_submission():\n",
        "    \"\"\"Создаем гибридный submission\"\"\"\n",
        "\n",
        "    print(\"Creating HYBRID space restoration solution...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Загружаем данные\n",
        "    filename = 'dataset_1937770_3.txt'\n",
        "    data = load_data(filename)\n",
        "    texts = data['text_no_spaces'].tolist()\n",
        "\n",
        "    print(f\"Loaded {len(texts)} texts\")\n",
        "\n",
        "    # Инициализируем гибридный восстановитель\n",
        "    restorer = HybridSpaceRestorer()\n",
        "\n",
        "    # Обучаем на данных\n",
        "    print(\"Training hybrid model...\")\n",
        "    restorer.fit(texts)\n",
        "\n",
        "    # Генерируем предсказания\n",
        "    print(\"Generating hybrid predictions...\")\n",
        "    predictions = []\n",
        "\n",
        "    for i, text in tqdm(enumerate(texts), total=len(texts)):\n",
        "        spaces = restorer.restore_spaces(text)\n",
        "        predictions.append(spaces)\n",
        "\n",
        "    # Создаем результат\n",
        "    data['predicted_positions'] = predictions\n",
        "    data['predicted_positions'] = data['predicted_positions'].apply(\n",
        "        lambda x: str(x) if x else '[]'\n",
        "    )\n",
        "\n",
        "    # Сохраняем\n",
        "    output_file = 'hybrid_submission.csv'\n",
        "    data[['id', 'predicted_positions']].to_csv(output_file, index=False)\n",
        "\n",
        "    print(f\"Saved to {output_file}\")\n",
        "\n",
        "    # Тестируем на примерах\n",
        "    print(\"\\nTesting hybrid model on examples:\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    test_cases = [\n",
        "        \"куплюайфон14про\",\n",
        "        \"сдаюквартирувцентреМосквы\",\n",
        "        \"ищуработуудаленновМоскве\",\n",
        "        \"новыйдивансдоставкойнедорого\",\n",
        "        \"отдамкошкувдобрыерукисрочно\"\n",
        "    ]\n",
        "\n",
        "    for text in test_cases:\n",
        "        spaces = restorer.restore_spaces(text)\n",
        "\n",
        "        # Восстанавливаем текст для демонстрации\n",
        "        if spaces:\n",
        "            result = list(text)\n",
        "            for pos in sorted(spaces, reverse=True):\n",
        "                if pos < len(result):\n",
        "                    result.insert(pos + 1, ' ')\n",
        "            restored = ''.join(result)\n",
        "        else:\n",
        "            restored = text\n",
        "\n",
        "        print(f\"Input:  {text}\")\n",
        "        print(f\"Output: {restored}\")\n",
        "        print(f\"Spaces: {spaces}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Анализ эффективности методов\n",
        "    print(\"\\nMethod effectiveness analysis:\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    sample_text = \"куплюайфон14просрочнонемедорого\"\n",
        "    methods = ['dictionary', 'viterbi', 'heuristics', 'patterns']\n",
        "\n",
        "    all_method_spaces = {}\n",
        "    for method in methods:\n",
        "        if method == 'dictionary':\n",
        "            spaces = restorer.dictionary_search(sample_text)\n",
        "        elif method == 'viterbi':\n",
        "            spaces = restorer.viterbi_search(sample_text)\n",
        "        elif method == 'heuristics':\n",
        "            spaces = restorer.russian_heuristics(sample_text)\n",
        "        elif method == 'patterns':\n",
        "            spaces = restorer.pattern_search(sample_text)\n",
        "\n",
        "        all_method_spaces[method] = spaces\n",
        "\n",
        "        # Демонстрация результата метода\n",
        "        if spaces:\n",
        "            result = list(sample_text)\n",
        "            for pos in sorted(spaces, reverse=True):\n",
        "                if pos < len(result):\n",
        "                    result.insert(pos + 1, ' ')\n",
        "            method_result = ''.join(result)\n",
        "        else:\n",
        "            method_result = sample_text\n",
        "\n",
        "        print(f\"{method:12}: {method_result}\")\n",
        "        print(f\"{' ':12}  Spaces: {spaces}\")\n",
        "\n",
        "    # Комбинированный результат\n",
        "    final_spaces = restorer.combine_results(sample_text, all_method_spaces)\n",
        "    if final_spaces:\n",
        "        result = list(sample_text)\n",
        "        for pos in sorted(final_spaces, reverse=True):\n",
        "            if pos < len(result):\n",
        "                result.insert(pos + 1, ' ')\n",
        "        final_result = ''.join(result)\n",
        "    else:\n",
        "        final_result = sample_text\n",
        "\n",
        "    print(f\"{'HYBRID':12}: {final_result}\")\n",
        "    print(f\"{' ':12}  Spaces: {final_spaces}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    result_df = create_hybrid_submission()\n",
        "\n",
        "    print(\"\\nHybrid solution completed!\")\n",
        "    print(\"Combined strengths of both approaches:\")\n",
        "    print(\"   • Fast dictionary search\")\n",
        "    print(\"   • Viterbi algorithm with Avito corpus\")\n",
        "    print(\"   • Linguistic heuristics\")\n",
        "    print(\"   • Pattern recognition\")\n",
        "    print(\"   • Intelligent result combination\")\n",
        "    print(\"Expected: Maximum F1 score improvement!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952,
          "referenced_widgets": [
            "184b3f6d8dee40b8bbccf3677c0794ae",
            "14a7118b467f4dd6a15d073add053de2",
            "6d59a3e5aa0c4936aae2b5ad8b7f5388",
            "0a8319ccdf6e4835b1239f552ac7162d",
            "48ae4bd5bc694c1b9882267f6991717b",
            "810eff9b8a094f36ac12d83a71a3524d",
            "784c32b5a9234462955961b70bf86eef",
            "81cf947a56224b63b0d014bf56599d43",
            "702dec1e5f6947cfa4b589b72518ea26",
            "8922e326991547edb8efe67774d8dcba",
            "cd1c0929cf7544ae8b7517c355e8f5a2"
          ]
        },
        "id": "6fA-dL3Rj7Lu",
        "outputId": "37e96475-387f-4e7d-e3ec-c95deb47d2e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating HYBRID space restoration solution...\n",
            "============================================================\n",
            "Loaded 1005 texts\n",
            "Training hybrid model...\n",
            "Обучен Avito-словарь на 1005 текстах\n",
            "Generating hybrid predictions...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1005 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "184b3f6d8dee40b8bbccf3677c0794ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to hybrid_submission.csv\n",
            "\n",
            "Testing hybrid model on examples:\n",
            "============================================================\n",
            "Input:  куплюайфон14про\n",
            "Output: куплю айфон 14про\n",
            "Spaces: [4, 9]\n",
            "--------------------------------------------------\n",
            "Input:  сдаюквартирувцентреМосквы\n",
            "Output: сдаюк ва ртиру вцентре Мо сквы \n",
            "Spaces: [4, 6, 11, 18, 20, 24]\n",
            "--------------------------------------------------\n",
            "Input:  ищуработуудаленновМоскве\n",
            "Output: ищур абот ууд але нно вМо скве \n",
            "Spaces: [3, 7, 10, 13, 16, 19, 23]\n",
            "--------------------------------------------------\n",
            "Input:  новыйдивансдоставкойнедорого\n",
            "Output: новыйд иван сдо ста вкой недорого\n",
            "Spaces: [5, 9, 12, 15, 19]\n",
            "--------------------------------------------------\n",
            "Input:  отдамкошкувдобрыерукисрочно\n",
            "Output: отд амк ошку вдо бры еруки срочно\n",
            "Spaces: [2, 5, 9, 12, 15, 20]\n",
            "--------------------------------------------------\n",
            "\n",
            "Method effectiveness analysis:\n",
            "============================================================\n",
            "dictionary  : куплюа йфон1 4просрочнон еме дорого\n",
            "              Spaces: [5, 10, 21, 24]\n",
            "viterbi     : куплю айфон 14 про срочно нем едорого\n",
            "              Spaces: [4, 9, 11, 14, 20, 23]\n",
            "heuristics  : куплюайфон14просрочноне м е до р о го\n",
            "              Spaces: [27, 23, 22, 24, 26, 28]\n",
            "patterns    : куплюайфон14просрочнонемедорого\n",
            "              Spaces: []\n",
            "HYBRID      : куплю айфон 14про срочно нем едорого\n",
            "              Spaces: [4, 9, 14, 20, 23]\n",
            "\n",
            "Hybrid solution completed!\n",
            "Combined strengths of both approaches:\n",
            "   • Fast dictionary search\n",
            "   • Viterbi algorithm with Avito corpus\n",
            "   • Linguistic heuristics\n",
            "   • Pattern recognition\n",
            "   • Intelligent result combination\n",
            "Expected: Maximum F1 score improvement!\n"
          ]
        }
      ]
    }
  ]
}